{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvigdorFeldman/Collab/blob/main/Cloud_Snake_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Index & RAG**"
      ],
      "metadata": {
        "id": "bD_Eugb9OLs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# INSTALLS\n",
        "# ============================\n",
        "!pip -q install nltk pymupdf requests\n",
        "\n",
        "# ============================\n",
        "# IMPORTS\n",
        "# ============================\n",
        "import re, math, os\n",
        "import requests\n",
        "import fitz  # PyMuPDF\n",
        "from collections import defaultdict\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt_tab\") # Added this line to download the missing resource\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQhrYZAR2YQF",
        "outputId": "e52b77b1-7576-446c-88c4-e7e1dde92bc4"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openai\n",
        "# import os\n",
        "# from openai import OpenAI\n",
        "# from google.colab import userdata\n",
        "\n",
        "# # TEMP: set in this session (better than hard-coding in functions)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API\")\n",
        "# client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rpdKLVPBn22e"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================\n",
        "# GOOGLE DRIVE URL HELPERS\n",
        "# ============================\n",
        "def extract_drive_file_id(url: str):\n",
        "    \"\"\"\n",
        "    Supports:\n",
        "    - https://drive.google.com/file/d/<ID>/view\n",
        "    - https://drive.google.com/open?id=<ID>\n",
        "    - https://drive.google.com/uc?id=<ID>&export=download\n",
        "    \"\"\"\n",
        "    m = re.search(r\"/file/d/([^/]+)\", url)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    m = re.search(r\"[?&]id=([^&]+)\", url)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    return None\n",
        "import re\n",
        "import requests\n",
        "\n",
        "def extract_drive_file_id(url: str):\n",
        "    m = re.search(r\"/file/d/([^/]+)\", url)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    m = re.search(r\"[?&]id=([^&]+)\", url)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    return None\n",
        "\n",
        "def drive_direct_download_url(url: str):\n",
        "    file_id = extract_drive_file_id(url)\n",
        "    if not file_id:\n",
        "        return url\n",
        "    return f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "\n",
        "def download_pdf_bytes(url: str, timeout=60):\n",
        "    session = requests.Session()\n",
        "    direct = drive_direct_download_url(url)\n",
        "\n",
        "    r = session.get(direct, stream=True, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    # If Drive returns HTML, try confirm token\n",
        "    content_type = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
        "    if \"text/html\" in content_type:\n",
        "        confirm_token = None\n",
        "        for k, v in session.cookies.items():\n",
        "            if k.startswith(\"download_warning\"):\n",
        "                confirm_token = v\n",
        "                break\n",
        "        if confirm_token:\n",
        "            r = session.get(direct + f\"&confirm={confirm_token}\", stream=True, timeout=timeout)\n",
        "            r.raise_for_status()\n",
        "\n",
        "    data = r.content\n",
        "    if not data.startswith(b\"%PDF\"):\n",
        "        raise ValueError(\"Downloaded content is not a PDF. Check sharing permissions (Anyone with the link can view).\")\n",
        "    return data\n",
        "\n",
        "def download_pdf_bytes(url: str, timeout=60):\n",
        "    \"\"\"\n",
        "    Downloads a PDF from:\n",
        "    - direct PDF URL, or\n",
        "    - Google Drive file URL (handles the confirm token when Drive warns about virus scan / large file)\n",
        "    \"\"\"\n",
        "    session = requests.Session()\n",
        "    direct = drive_direct_download_url(url)\n",
        "\n",
        "    # First request\n",
        "    r = session.get(direct, stream=True, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    # Google Drive sometimes requires a confirm token (returns HTML)\n",
        "    content_type = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
        "    if \"text/html\" in content_type or \"drive.google.com\" in r.url:\n",
        "        # try to find confirm token in cookies\n",
        "        confirm_token = None\n",
        "        for k, v in session.cookies.items():\n",
        "            if k.startswith(\"download_warning\"):\n",
        "                confirm_token = v\n",
        "                break\n",
        "\n",
        "        if confirm_token:\n",
        "            r = session.get(direct + f\"&confirm={confirm_token}\", stream=True, timeout=timeout)\n",
        "            r.raise_for_status()\n",
        "        # else: could still be HTML if permissions are not public\n",
        "\n",
        "    data = r.content\n",
        "    # quick sanity check: PDFs usually start with %PDF\n",
        "    if not data.startswith(b\"%PDF\"):\n",
        "        raise ValueError(\n",
        "            \"Downloaded content is not a PDF. \"\n",
        "            \"Make sure the Drive file is shared as 'Anyone with the link can view'.\"\n",
        "        )\n",
        "    return data\n",
        "\n",
        "# ============================\n",
        "# PDF TEXT EXTRACTION\n",
        "# ============================\n",
        "def pdf_bytes_to_text(pdf_bytes: bytes, max_chars=20000):\n",
        "    doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
        "    parts = []\n",
        "    for page in doc:\n",
        "        parts.append(page.get_text(\"text\"))\n",
        "    text = re.sub(r\"\\s+\", \" \", \" \".join(parts)).strip()\n",
        "    return text[:max_chars]\n",
        "\n",
        "# ============================\n",
        "# LOAD DOCUMENTS FROM URLS\n",
        "# ============================\n",
        "def load_papers_from_urls(urls, max_chars=20000):\n",
        "    documents = []\n",
        "    kept_urls = []\n",
        "    for url in urls:\n",
        "        try:\n",
        "            pdf_data = download_pdf_bytes(url)\n",
        "            text = pdf_bytes_to_text(pdf_data, max_chars=max_chars)\n",
        "            documents.append(text)\n",
        "            kept_urls.append(url)\n",
        "            print(\"Loaded:\", url)\n",
        "        except Exception as e:\n",
        "            print(\"FAILED:\", url, \"|\", str(e))\n",
        "    return documents, kept_urls\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EnsBaSCz2IG4"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# PREPROCESSING\n",
        "# ============================\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(text: str):\n",
        "    text = re.sub(r\"[^a-zA-Z0-9 ]\", \" \", text)\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    tokens = [stemmer.stem(t) for t in tokens]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "etlirofJ7Rr0"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The chosen stop wordes: \",stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMvZr3O7xalz",
        "outputId": "fc3b54c7-9783-48c1-c510-725c5cd52150"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The chosen stop wordes:  {\"haven't\", 'yourself', \"couldn't\", \"mightn't\", 'themselves', 'up', 'me', 'not', 'above', 'yourselves', 'then', 'under', 'because', \"didn't\", 'out', \"that'll\", 'the', 'such', \"hasn't\", 'a', 'shouldn', 'theirs', 'any', \"should've\", \"he'll\", 'there', \"you'll\", 'whom', \"you've\", 'are', 'those', 'here', 'was', 'between', 'aren', 'after', 'from', 'will', \"he's\", \"i'd\", 'yours', 'll', 'doesn', 'these', 'but', 'by', 'doing', 'isn', 'to', 'having', \"we'll\", 's', 'of', \"won't\", \"you're\", 'until', 'y', 'mightn', 'more', \"we've\", 'some', 'before', \"they're\", 'now', 'needn', 'she', 'be', 'them', \"needn't\", 'through', 've', 'weren', 'herself', 'other', 'below', 'so', 'mustn', 'no', 'nor', 'won', 'hadn', 'ourselves', \"they've\", 'off', 'while', 'am', 'your', 'again', 'being', \"wasn't\", 'own', 'himself', 'most', 'how', 'were', \"i've\", 'we', \"weren't\", 't', 'over', 'been', 'same', 'does', 'just', 'its', 'for', 'is', 'o', 'hasn', 'their', 'didn', \"shan't\", 'he', 'd', 'what', \"i'm\", 'and', 'or', \"they'll\", \"doesn't\", 'have', 'ours', \"wouldn't\", 'as', 'hers', \"mustn't\", 'wasn', \"don't\", 'myself', 'both', 'down', 'once', 'do', 'don', 'my', 'it', 'has', 'an', 'all', 'can', 'ma', 'with', 'should', 'had', 'itself', \"it'd\", \"aren't\", 'shan', \"she'll\", 'that', \"it'll\", 'her', \"you'd\", 'in', 'did', \"we're\", 'into', 'which', 'than', 'at', \"hadn't\", 'about', 'm', 'on', 'couldn', 'him', 'during', 'i', 'our', 're', 'when', 'you', \"isn't\", 'ain', 'who', \"she's\", \"it's\", 'haven', 'they', 'his', \"i'll\", 'each', 'this', \"shouldn't\", \"she'd\", \"they'd\", 'against', 'where', 'few', 'only', 'why', 'too', 'very', \"we'd\", \"he'd\", 'wouldn', 'further', 'if'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def TFIDF(tf, df, n):\n",
        "    return tf * math.log(n / df)\n",
        "# MODULAR URL INDEX (keeps your TF/DF/build pattern)\n",
        "# ============================\n",
        "\n",
        "def TF_urls(documents, urls):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      doc_term_counts: list of dicts, aligned with urls:\n",
        "        doc_term_counts[i][term] = tf in document i\n",
        "    \"\"\"\n",
        "    doc_term_counts = []\n",
        "    for text in documents:\n",
        "        counts = defaultdict(int)\n",
        "        for term in preprocess(text):\n",
        "            counts[term] += 1\n",
        "        doc_term_counts.append(counts)\n",
        "    return doc_term_counts\n",
        "\n",
        "def DF_urls(doc_term_counts):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      df[term] = number of documents containing term\n",
        "    \"\"\"\n",
        "    df = defaultdict(int)\n",
        "    for counts in doc_term_counts:\n",
        "        for term in counts.keys():\n",
        "            df[term] += 1\n",
        "    return df\n",
        "\n",
        "def build_url_list_index(doc_term_counts, urls):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      index_urls[term] = [url1, url2, ...] (sorted)\n",
        "    \"\"\"\n",
        "    index_urls = defaultdict(set)\n",
        "\n",
        "    for i, counts in enumerate(doc_term_counts):\n",
        "        url = urls[i]\n",
        "        for term in counts.keys():              # presence is enough for URL list\n",
        "            index_urls[term].add(url)\n",
        "\n",
        "    return {term: sorted(list(u_set)) for term, u_set in index_urls.items()}\n",
        "\n",
        "def build_stats_index(doc_term_counts, urls, df, n_docs):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      stats[term][url] = {\"count\": tf, \"rank\": tfidf}\n",
        "    \"\"\"\n",
        "    stats = defaultdict(dict)\n",
        "\n",
        "    for i, counts in enumerate(doc_term_counts):\n",
        "        url = urls[i]\n",
        "        for term, tf in counts.items():\n",
        "            stats[term][url] = {\n",
        "                \"count\": tf,\n",
        "                \"rank\": TFIDF(tf, df[term], n_docs)\n",
        "            }\n",
        "\n",
        "    return stats\n",
        "\n",
        "def build_inverted_index_urls(documents, urls, with_tfidf=True):\n",
        "    \"\"\"\n",
        "    Main builder (modular):\n",
        "      - index_urls: term -> list of urls that contain the term\n",
        "      - stats (optional): term -> url -> {count, rank}\n",
        "      - df: term -> doc frequency\n",
        "    \"\"\"\n",
        "    n_docs = len(documents)\n",
        "\n",
        "    # 1) TF per document\n",
        "    doc_term_counts = TF_urls(documents, urls)\n",
        "\n",
        "    # 2) DF per term\n",
        "    df = DF_urls(doc_term_counts)\n",
        "\n",
        "    # 3) term -> urls list\n",
        "    index_urls = build_url_list_index(doc_term_counts, urls)\n",
        "\n",
        "    if not with_tfidf:\n",
        "        return index_urls, None, df\n",
        "\n",
        "    stats = build_stats_index(doc_term_counts, urls, df, n_docs)\n",
        "    return index_urls, stats, df\n",
        "\n",
        "def retrieve_urls(query, index_urls, stats=None, top_k=3):\n",
        "    q_terms = preprocess(query)\n",
        "    scores = defaultdict(float)\n",
        "    for term in q_terms:\n",
        "        if term not in index_urls:\n",
        "            continue\n",
        "        for url in index_urls[term]:\n",
        "            if stats is None:\n",
        "                scores[url] += 1.0  # simple matching\n",
        "            else:\n",
        "                # add rank if available, otherwise fallback to +1\n",
        "                scores[url] += stats.get(term, {}).get(url, {}).get(\"rank\", 1.0)\n",
        "\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
        "    return ranked"
      ],
      "metadata": {
        "id": "SpWj9N53yGGi"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers_urls = [\n",
        "    \"https://drive.google.com/file/d/11ANjTBB6MGLgBQFg4q25YChjDYPrxLzQ/view\",\n",
        "    \"https://drive.google.com/file/d/1kgwtzK4TWKMFKnOxv8u2r1ad6z1wvLNf/view\",\n",
        "    \"https://drive.google.com/file/d/14vugPbpa8AdA-t-Cwgsdh8tuUocrhoaq/view\",\n",
        "    \"https://drive.google.com/file/d/1eDEw6frpO2aZKHzHrtjnxXiGjk-89pzv/view\",\n",
        "    \"https://drive.google.com/file/d/1aSOVQ22W8jH3aRAa9RijJZZ0PM1DUj4-/view\"\n",
        "]"
      ],
      "metadata": {
        "id": "qg8iZo6Dy6Di"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents, urls = load_papers_from_urls(papers_urls, max_chars=200000)\n",
        "print(\"Loaded papers:\", len(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvqpvGmlq-QL",
        "outputId": "b807754a-0a6f-489b-8889-2b5a81e8f9e6",
        "collapsed": true
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: https://drive.google.com/file/d/11ANjTBB6MGLgBQFg4q25YChjDYPrxLzQ/view\n",
            "Loaded: https://drive.google.com/file/d/1kgwtzK4TWKMFKnOxv8u2r1ad6z1wvLNf/view\n",
            "Loaded: https://drive.google.com/file/d/14vugPbpa8AdA-t-Cwgsdh8tuUocrhoaq/view\n",
            "Loaded: https://drive.google.com/file/d/1eDEw6frpO2aZKHzHrtjnxXiGjk-89pzv/view\n",
            "Loaded: https://drive.google.com/file/d/1aSOVQ22W8jH3aRAa9RijJZZ0PM1DUj4-/view\n",
            "Loaded papers: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_urls, stats,_ = build_inverted_index_urls(documents, urls, with_tfidf=True)"
      ],
      "metadata": {
        "id": "fg8hf1ZzrBCD"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================\n",
        "# # RAG GENERATION WITH OPENAI (URL-based)\n",
        "# # ============================\n",
        "# url_to_doc = {u: i for i, u in enumerate(urls)}\n",
        "# def rag_answer(query, index_urls, documents, urls, stats=None, top_k=3):\n",
        "#     \"\"\"\n",
        "#     index_urls: term -> [url1, url2, ...]\n",
        "#     documents : list of extracted text, aligned with urls\n",
        "#     urls      : list of urls, same length/order as documents\n",
        "#     stats     : optional term -> url -> {count, rank} for TF-IDF scoring\n",
        "#     \"\"\"\n",
        "#     ranked = retrieve_urls(query, index_urls, stats=stats, top_k=top_k)  # [(url, score), ...]\n",
        "\n",
        "#     # build context from the matching URLs\n",
        "#     context_parts = []\n",
        "#     for url, score in ranked:\n",
        "#         doc_idx = url_to_doc[url]\n",
        "#         text = documents[doc_idx]\n",
        "#         context_parts.append(f\"URL: {url}\\nScore: {score:.4f}\\nContent:\\n{text[:2000]}\")\n",
        "\n",
        "#     context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
        "\n",
        "#     prompt = f\"\"\"\n",
        "# Answer the question using ONLY the following academic paper excerpts.\n",
        "\n",
        "# {context}\n",
        "\n",
        "# Question: {query}\n",
        "\n",
        "# Rules:\n",
        "# - If the context is insufficient, say you don't have enough information from the provided papers.\n",
        "# - Do not use outside knowledge.\n",
        "# \"\"\"\n",
        "\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"gpt-4o-mini\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "#     )\n",
        "\n",
        "#     return response.choices[0].message.content\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9WTzJ5Yy21ZL"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- INSTALLATION (Run first - make sure it's the latest version) ---\n",
        "!pip install -q --upgrade google-genai\n",
        "\n",
        "# --- IMPORTS ---\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata # Colab specific module for accessing secrets\n",
        "import os\n",
        "\n",
        "# --- 1. Load Gemini Client (Secure using Colab Secrets) ---\n",
        "# Initialize the key and model globals\n",
        "gemini_model = None\n",
        "client = None\n",
        "\n",
        "try:\n",
        "    # 1a. Attempt to retrieve the key from Colab Secrets\n",
        "    gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "    if gemini_key:\n",
        "        # Use genai.configure() which is the robust way to set the API key globally\n",
        "        genai.configure(api_key=gemini_key)\n",
        "\n",
        "        # We can still get a client object, but often it's cleaner to use the\n",
        "        # GenerativeModel class directly after configure()\n",
        "        # client = genai.Client() # This should work now, but we don't strictly need it\n",
        "\n",
        "        # 1b. Initialize the Gemini Model object for RAG generation\n",
        "        # Since genai.configure() was called, the key is automatically used here\n",
        "        gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "        print(\"‚úÖ Gemini Client and Model initialized successfully using Colab Secret (key is secured).\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è GEMINI_API_KEY not found in Colab Secrets. Cloud AI disabled.\")\n",
        "        print(\"ACTION: Click the 'üîë' icon on the left to add your key as a secret named 'GEMINI_API_KEY'.\")\n",
        "\n",
        "except NameError:\n",
        "    # Handles cases where the code is not run in a Colab environment\n",
        "    print(\"‚ö†Ô∏è Colab userdata module not available. CLOUD AI disabled.\")\n",
        "except Exception as e:\n",
        "    # Catches any other exceptions during configuration or model loading\n",
        "    print(f\"‚ùå Error initializing Gemini: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EChaY1gDeBet",
        "outputId": "f7a9234b-2508-4ac0-821b-49529be94101"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gemini Client and Model initialized successfully using Colab Secret (key is secured).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_to_doc = {u: i for i, u in enumerate(urls)}"
      ],
      "metadata": {
        "id": "Zf_E4oDhjmzQ"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# RAG GENERATION WITH GEMINI API\n",
        "# ============================\n",
        "# Assumes 'gemini_model' and 'url_to_doc' are available globally\n",
        "\n",
        "def rag_answer(query, index_urls, documents, urls, stats=None, top_k=3):\n",
        "    \"\"\"\n",
        "    Performs RAG generation using the Gemini 2.5 Flash model.\n",
        "    \"\"\"\n",
        "    global gemini_model\n",
        "\n",
        "    if gemini_model is None:\n",
        "        return \"ERROR: Gemini Model failed to initialize. Please check your API key and setup cell.\"\n",
        "\n",
        "    # --- 1. RETRIEVAL STEP (Remains UNCHANGED) ---\n",
        "    ranked = retrieve_urls(query, index_urls, stats=stats, top_k=top_k)  # [(url, score), ...]\n",
        "\n",
        "    # --- 2. CONTEXT BUILDING STEP (Remains UNCHANGED) ---\n",
        "    context_parts = []\n",
        "    if not ranked:\n",
        "        return \"I couldn't find any relevant academic paper excerpts to answer your question.\"\n",
        "\n",
        "    for url, score in ranked:\n",
        "        doc_idx = url_to_doc.get(url)\n",
        "        if doc_idx is not None:\n",
        "            text = documents[doc_idx]\n",
        "            # Truncate text for prompt size\n",
        "            context_parts.append(f\"URL: {url}\\nScore: {score:.4f}\\nContent:\\n{text[:2000]}\")\n",
        "\n",
        "    context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
        "\n",
        "    # --- 3. PROMPT CREATION (Using System Instruction) ---\n",
        "    # Gemini models perform well with System Instructions\n",
        "\n",
        "    # The main user content (context + question)\n",
        "    user_content = f\"\"\"\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\"\"\"\n",
        "\n",
        "    # --- 4. GENERATION STEP (The Key Change to Gemini SDK) ---\n",
        "    try:\n",
        "        response = gemini_model.generate_content(\n",
        "            contents=[user_content],\n",
        "            config=genai.types.GenerateContentConfig(\n",
        "                # Use system instruction to set the model's behavior and rules\n",
        "                system_instruction=(\n",
        "                    \"You are an expert ecological research assistant. \"\n",
        "                    \"Answer the question using ONLY the provided academic paper excerpts. \"\n",
        "                    \"If the context is insufficient, state clearly that you don't have enough information from the provided papers. \"\n",
        "                    \"Do not use outside knowledge.\"\n",
        "                ),\n",
        "                max_output_tokens=512, # Limit output length for cost/speed\n",
        "                temperature=0.1        # Lower temperature promotes factual, grounded responses\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"ERROR during Gemini API call: {e}\""
      ],
      "metadata": {
        "id": "43Ss9G4kdvEy"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Screens**"
      ],
      "metadata": {
        "id": "rD9-eA8vOB8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First Screen Upload Photos with AI\n",
        "\n",
        "# ============================================================================\n",
        "# PART 0: IMPORTS AND INITIAL SETUP\n",
        "# ============================================================================\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from PIL import Image as PILImage\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, Image, clear_output, Javascript\n",
        "from google.colab import userdata # For secure access to API key (Secrets)\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Try to import Gemini/GenAI related tools\n",
        "try:\n",
        "    from google import genai\n",
        "    from google.genai import types\n",
        "except ImportError:\n",
        "    print(\"WARNING: google-genai not installed. Only local AI will be available.\")\n",
        "    pass\n",
        "\n",
        "# ============================================================================\n",
        "# PART 1: AI MODEL INITIALIZATION (SECURE CLOUD + LOCAL FALLBACK)\n",
        "# ============================================================================\n",
        "\n",
        "# --- Global Variables for AI Clients and Models ---\n",
        "gemini_client = None\n",
        "loaded_model = None\n",
        "loaded_processor = None\n",
        "label_names = []\n",
        "\n",
        "MODEL_HUB_NAME = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "\n",
        "# --- 1. Load Gemini Client (Secure using Colab Secrets) ---\n",
        "try:\n",
        "    # Tries to load the key securely from Colab Secrets\n",
        "    gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "    if gemini_key:\n",
        "        gemini_client = genai.Client(api_key=gemini_key)\n",
        "        #print(\"‚úÖ Gemini Client initialized successfully using Colab Secret (key is secured).\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è GEMINI_API_KEY not found in Colab Secrets. CLOUD AI disabled.\")\n",
        "except NameError:\n",
        "    print(\"‚ö†Ô∏è Colab userdata module not available (not in Colab?). CLOUD AI disabled.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing Gemini: {e}.\")\n",
        "\n",
        "# --- 2. Load MobileNet (Local Fallback Model) ---\n",
        "try:\n",
        "    # Load Label Names\n",
        "    from datasets import load_dataset\n",
        "    dataset = load_dataset(\"BrandonFors/Plant-Diseases-PlantVillage-Dataset\", split=\"train\")\n",
        "    label_names = dataset.features['label'].names\n",
        "except Exception:\n",
        "    label_names = [f\"Class {i}\" for i in range(38)]\n",
        "\n",
        "try:\n",
        "    # Load Model and Processor\n",
        "    loaded_processor = AutoImageProcessor.from_pretrained(MODEL_HUB_NAME)\n",
        "    loaded_model = AutoModelForImageClassification.from_pretrained(\n",
        "        MODEL_HUB_NAME, num_labels=len(label_names), ignore_mismatched_sizes=True\n",
        "    )\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    loaded_model.to(device)\n",
        "    #print(\"‚úÖ Local MobileNet loaded successfully for Fallback.\")\n",
        "except Exception as e:\n",
        "    loaded_model = None\n",
        "    # print(f\"‚ùå Error loading local MobileNet. Fallback disabled. Error: {e}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 2: CORE AI FUNCTIONS (GEMINI & MOBILENET)\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_image_with_gemini(image_bytes):\n",
        "    \"\"\"\n",
        "    Sends image to Gemini and returns detailed analysis formatted as Markdown.\n",
        "    The prompt is adjusted for a concise, structured (table + list) English output.\n",
        "    \"\"\"\n",
        "    global gemini_client\n",
        "\n",
        "    if gemini_client is None:\n",
        "        return \"Error: Gemini Client is not initialized (missing key/initialization error).\"\n",
        "\n",
        "    try:\n",
        "        image = PILImage.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        return f\"Error loading image: {e}\"\n",
        "\n",
        "    # --- ADJUSTED PROMPT FOR STRUCTURED ENGLISH OUTPUT ---\n",
        "    # System Instruction: Expert role and mandatory Markdown format\n",
        "    system_instruction = (\n",
        "        \"You are an expert plant disease diagnostician. Answer in English. \"\n",
        "        \"**Return the result in a structured Markdown format containing only a summary table and a list of bullet points.**\"\n",
        "    )\n",
        "\n",
        "    # User Prompt: Defines the structure required for clean UI display\n",
        "    prompt = (\n",
        "        \"Analyze the leaf image, and provide the results **in the following exact format**: \"\n",
        "        \"0. Write at most 4 lines:\"\n",
        "        \"1. A **h3 heading** in the format: 'üåø Plant Analysis: [Plant Name]'. \"\n",
        "        \"2. A **Markdown Table** with two columns ('Characteristic' and 'Status/Detail') including 4 rows: 'Plant Type', 'Health Status' (Healthy/Sick), 'Identification' (Disease or natural trait like variegation), and 'Diagnosis' (a brief detail on the leaf's condition). \"\n",
        "        \"3. A **h4 heading** named 'üí° Care Recommendations for Beauty and Vitality:'. \"\n",
        "        \"4. A **bulleted list** of 2 short and clear care recommendations.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = gemini_client.models.generate_content(\n",
        "            model='gemini-2.5-flash',\n",
        "            contents=[prompt, image],\n",
        "            config=types.GenerateContentConfig(\n",
        "                system_instruction=system_instruction\n",
        "            )\n",
        "        )\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error communicating with Gemini API: {e}\"\n",
        "\n",
        "def predict_disease_from_bytes(image_bytes, model, processor, label_names, top_k=3):\n",
        "    \"\"\" Performs prediction using the local MobileNet model. \"\"\"\n",
        "    if model is None:\n",
        "        return [(\"Error: Local AI Model is not loaded.\", 0)]\n",
        "\n",
        "    try:\n",
        "        image = PILImage.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
        "        inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "        device = model.device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]\n",
        "        top_probs, top_indices = torch.topk(probabilities, k=top_k)\n",
        "\n",
        "        results = []\n",
        "        for prob, idx in zip(top_probs, top_indices):\n",
        "            disease_name = label_names[idx.item()]\n",
        "            confidence = prob.item()\n",
        "            results.append((disease_name, confidence))\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        return [(\"Error processing image with MobileNet: \" + str(e), 0)]\n",
        "\n",
        "def analyze_image_unified(image_bytes):\n",
        "    \"\"\" Decides whether to use Gemini or MobileNet. \"\"\"\n",
        "    global gemini_client, loaded_model, loaded_processor, label_names\n",
        "\n",
        "    # 1. Try Gemini (Priority)\n",
        "    if gemini_client:\n",
        "        result_text = analyze_image_with_gemini(image_bytes)\n",
        "        return result_text, \"GEMINI_CLOUD\"\n",
        "\n",
        "    # 2. Use MobileNet Local (Fallback)\n",
        "    elif loaded_model is not None:\n",
        "        results = predict_disease_from_bytes(image_bytes, loaded_model, loaded_processor, label_names, top_k=3)\n",
        "\n",
        "        # Format MobileNet results into readable HTML\n",
        "        result_html = \"<h4>Local MobileNet Analysis Results:</h4><ul>\"\n",
        "        for j, (disease, confidence) in enumerate(results):\n",
        "            style = \"font-weight: bold; color: #38761d;\" if j == 0 else \"color: #555;\"\n",
        "            result_html += f'<li><span style=\"{style}\">{disease}:</span> {confidence:.2%}</li>'\n",
        "        result_html += \"</ul>\"\n",
        "\n",
        "        return result_html, \"LOCAL\"\n",
        "\n",
        "    # 3. Complete Failure\n",
        "    else:\n",
        "        return \"Error: Failed to load both Gemini (missing key) and MobileNet (local loading error).\", \"ERROR\"\n",
        "\n",
        "# ============================================================================\n",
        "# PART 3: CAMERA CAPTURE FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def take_photo_to_bytes(quality=0.8):\n",
        "    \"\"\" Captures photo using webcam and returns the image content as bytes. \"\"\"\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture Photo';\n",
        "            capture.style.cssText = 'background-color: #6aa84f; color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; margin-top: 10px;';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            video.style.maxWidth = '100%';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "        ''')\n",
        "    display(js)\n",
        "\n",
        "    try:\n",
        "        data = eval_js('takePhoto({})'.format(quality))\n",
        "        binary = b64decode(data.split(',')[1])\n",
        "        return binary\n",
        "    except Exception as err:\n",
        "        return None\n",
        "\n",
        "# ============================================================================\n",
        "# PART 4: UI/WIDGETS AND EVENT HANDLERS (ALL ENGLISH)\n",
        "# ============================================================================\n",
        "\n",
        "# --- Global variables to store uploaded image data and current index ---\n",
        "uploaded_images = []\n",
        "current_image_index = 0\n",
        "\n",
        "# --- 1. Global CSS Definitions (Retained for style) ---\n",
        "css_style = \"\"\"\n",
        "<style>\n",
        "    .widget-vbox.main-container {\n",
        "        background-color: #ffffff !important; border: 1px solid #e0e0e0 !important; border-radius: 10px !important;\n",
        "        padding: 40px !important; margin: 20px auto !important;\n",
        "        font-family: Arial, sans-serif !important; text-align: center !important; box-shadow: 0 4px 12px rgba(0,0,0,0.05);\n",
        "    }\n",
        "    body { background-color: #f7fff7 !important; }\n",
        "    h3 { color: #38761d !important; font-weight: bold !important; margin-top: 10px !important; margin-bottom: 5px !important; }\n",
        "    h4 { color: #38761d !important; margin-top: 15px !important; margin-bottom: 5px !important; }\n",
        "    p.subtitle { color: #555 !important; font-size: 14px !important; margin-bottom: 30px !important; }\n",
        "    .camera-icon-container { width: 80px; height: 80px; background-color: #e6f7e6; border-radius: 50%; display: flex; justify-content: center; align-items: center; margin: 0 auto 15px auto; border: 2px solid #6aa84f; }\n",
        "    .camera-icon { font-size: 36px !important; color: #6aa84f !important; }\n",
        "    .upload-icon { font-size: 36px !important; color: #6aa84f !important; margin-bottom: 10px !important; }\n",
        "    .drop-zone-vbox { border: 2px dashed #93c47d !important; border-radius: 8px !important; padding: 40px 20px !important; background-color: #fafff7 !important; margin-bottom: 30px !important; }\n",
        "    .drop-zone-text p { color: #555 !important; margin: 0 !important; line-height: 1.5 !important; }\n",
        "    .widget-upload .btn.btn-success { background-color: #6aa84f !important; border-color: #6aa84f !important; color: white !important; padding: 8px 20px !important; font-weight: bold !important; margin-top: 15px !important; }\n",
        "    .widget-upload .btn.btn-success:hover { background-color: #38761d !important; border-color: #38761d !important; }\n",
        "    .image-display-output { margin-top: 20px; margin-bottom: 20px; border: 1px solid #ddd; border-radius: 5px; padding: 10px; background-color: #fff; max-width: 300px; min-height: 50px; margin-left: auto; margin-right: auto; display: flex; flex-direction: column; justify-content: center; align-items: center; }\n",
        "    .widget-button { border-radius: 4px; font-size: 14px; padding: 6px 12px; margin: 0 5px; }\n",
        "    .widget-button.mod-info { background-color: #f0f8ff !important; border: 1px solid #cce5ff !important; color: #007bff !important; }\n",
        "    .widget-button.mod-danger { background-color: #FF0000 !important; border: 1px solid #dee2e6 !important; color: #ffffff !important; }\n",
        "    .widget-button.mod-primary { background-color: #6aa84f !important; border-color: #6aa84f !important; color: white !important; }\n",
        "    .widget-button:disabled { opacity: 0.6; }\n",
        "    .hint-text { font-size: 13px !important; color: #777 !important; margin-top: 25px !important; margin-bottom: 0 !important; }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# --- 2. Create File Upload Widget ---\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',\n",
        "    multiple=True,\n",
        "    description='Choose File(s)',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='auto', margin='10px auto 10px auto')\n",
        ")\n",
        "\n",
        "# --- 3. Create HTML Widgets for Content Segmentation ---\n",
        "# Header Content\n",
        "header_content = widgets.VBox([\n",
        "    widgets.HTML(value=\"\"\"<div class=\"camera-icon-container\"><div class=\"camera-icon\">üì∏</div></div>\"\"\"),\n",
        "    widgets.HTML(value=\"<h3>Upload Plant Photo(s)</h3>\"),\n",
        "    widgets.HTML(value='<p class=\"subtitle\">Take a clear photo(s) of your plant to analyze its health</p>')\n",
        "], layout=widgets.Layout(align_items='center'))\n",
        "\n",
        "# Drop Zone Content\n",
        "drop_zone_text_content = widgets.VBox([\n",
        "    widgets.HTML(value=\"\"\"<div class=\"upload-icon\">‚¨ÜÔ∏è</div>\"\"\"),\n",
        "    widgets.HTML(value=\"\"\"<div class=\"drop-zone-text\"><p>Click to upload or drag and drop</p></div>\"\"\")\n",
        "], layout=widgets.Layout(align_items='center', margin='0 0 10px 0'))\n",
        "\n",
        "# Camera Capture Button\n",
        "btn_capture = widgets.Button(\n",
        "    description='Capture Photo',\n",
        "    button_style='primary',\n",
        "    icon='camera',\n",
        "    layout=widgets.Layout(width='auto', margin='20px auto 0px auto')\n",
        ")\n",
        "\n",
        "# Footer Content\n",
        "footer_content = widgets.HTML(\n",
        "    value=\"\"\"<div class=\"hint-text\">Use the button above to capture a photo directly from your webcam.</div>\"\"\"\n",
        ")\n",
        "\n",
        "# Output widget for displaying the selected image\n",
        "image_display_output = widgets.Output()\n",
        "image_display_output.add_class('image-display-output')\n",
        "\n",
        "# Navigation Buttons\n",
        "btn_prev = widgets.Button(\n",
        "    description='Previous', disabled=True, button_style='info', icon='arrow-left',\n",
        "    layout=widgets.Layout(width='auto', flex='1 1 auto', margin='0 5px')\n",
        ")\n",
        "bnt_next = widgets.Button(\n",
        "    description='Next', disabled=True, button_style='info', icon='arrow-right',\n",
        "    layout=widgets.Layout(width='auto', flex='1 1 auto', margin='0 5px')\n",
        ")\n",
        "btn_remove = widgets.Button(\n",
        "    description='Remove Photo', disabled=True, button_style='danger', icon='trash',\n",
        "    layout=widgets.Layout(width='auto', flex='1 1 auto', margin='0 5px')\n",
        ")\n",
        "\n",
        "# Analysis Widgets\n",
        "btn_analyze = widgets.Button(\n",
        "    description='‚ú® Analyze Photos (AI) ‚ú®',\n",
        "    button_style='success',\n",
        "    icon='flask',\n",
        "    layout=widgets.Layout(width='auto', margin='20px auto 10px auto')\n",
        ")\n",
        "\n",
        "analysis_output = widgets.Output()\n",
        "\n",
        "# --- 4. Event Handler Functions ---\n",
        "\n",
        "def update_image_display():\n",
        "    global current_image_index, uploaded_images\n",
        "\n",
        "    with image_display_output:\n",
        "        image_display_output.clear_output(wait=True)\n",
        "        if uploaded_images and 0 <= current_image_index < len(uploaded_images):\n",
        "            display(Image(data=uploaded_images[current_image_index], width=200))\n",
        "            display(\n",
        "                HTML(\n",
        "                    f\"<span style='font-size:12px; color:#777; margin-top:10px;'>Image {current_image_index + 1} of {len(uploaded_images)}</span>\"\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            display(HTML(\"<span>No image selected.</span>\"))\n",
        "\n",
        "    is_image_present = bool(uploaded_images)\n",
        "    btn_prev.disabled = (current_image_index == 0) or not is_image_present\n",
        "    bnt_next.disabled = (current_image_index == len(uploaded_images) - 1) or not is_image_present\n",
        "    btn_remove.disabled = not is_image_present\n",
        "\n",
        "def on_upload_change(change):\n",
        "    global uploaded_images, current_image_index\n",
        "\n",
        "    new_files_content = []\n",
        "    if change.new:\n",
        "        file_list = list(change.new.values())\n",
        "        if file_list:\n",
        "            for file_info in file_list:\n",
        "                file_content = file_info['content']\n",
        "                new_files_content.append(file_content)\n",
        "\n",
        "    if new_files_content:\n",
        "        old_length = len(uploaded_images)\n",
        "        uploaded_images.extend(new_files_content)\n",
        "        current_image_index = old_length\n",
        "        update_image_display()\n",
        "    elif not uploaded_images:\n",
        "        update_image_display()\n",
        "\n",
        "def on_capture_click(b):\n",
        "    global uploaded_images, current_image_index\n",
        "\n",
        "    b.disabled = True\n",
        "    b.description = 'Capturing...'\n",
        "\n",
        "    captured_bytes = take_photo_to_bytes()\n",
        "\n",
        "    b.description = 'Capture Photo'\n",
        "    b.disabled = False\n",
        "\n",
        "    if captured_bytes:\n",
        "        uploaded_images.append(captured_bytes)\n",
        "        current_image_index = len(uploaded_images) - 1\n",
        "        update_image_display()\n",
        "\n",
        "def on_prev_click(b):\n",
        "    global current_image_index\n",
        "    if current_image_index > 0:\n",
        "        current_image_index -= 1\n",
        "        update_image_display()\n",
        "\n",
        "def on_next_click(b):\n",
        "    global current_image_index\n",
        "    if current_image_index < len(uploaded_images) - 1:\n",
        "        current_image_index += 1\n",
        "        update_image_display()\n",
        "\n",
        "def on_remove_click(b):\n",
        "    global uploaded_images, current_image_index\n",
        "    if uploaded_images and 0 <= current_image_index < len(uploaded_images):\n",
        "        del uploaded_images[current_image_index]\n",
        "\n",
        "        if uploaded_images:\n",
        "            if current_image_index >= len(uploaded_images):\n",
        "                current_image_index = len(uploaded_images) - 1\n",
        "        else:\n",
        "\n",
        "            current_image_index = 0\n",
        "\n",
        "\n",
        "        update_image_display()\n",
        "def on_analyze_click(b):\n",
        "    global uploaded_images\n",
        "\n",
        "    # --- 1. Clear the entire analysis_output just ONCE at the start ---\n",
        "    with analysis_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        if not uploaded_images:\n",
        "            display(HTML(\"<h2>üö´ Error: Please upload or capture an image first.</h2>\"))\n",
        "            return\n",
        "\n",
        "        display(HTML(f\"<h2>üî¨ Analyzing {len(uploaded_images)} Images:</h2>\"))\n",
        "\n",
        "    # Prepare a dedicated widget for the current image's loading state and results\n",
        "    # We will display the results sequentially into this main output area.\n",
        "\n",
        "    for i, img_bytes in enumerate(uploaded_images):\n",
        "\n",
        "        # We use a temporary output widget to display the loading status for the current image.\n",
        "        loading_status_output = widgets.Output()\n",
        "\n",
        "        with analysis_output:\n",
        "            # Display image and title directly into the main output\n",
        "            display(HTML(f\"<h3>Image {i+1} of {len(uploaded_images)}:</h3>\"))\n",
        "            display(Image(data=img_bytes, width=200))\n",
        "\n",
        "            # Display the loading message placeholder\n",
        "            display(loading_status_output)\n",
        "\n",
        "        with loading_status_output:\n",
        "            # 2. Display the loading message into the temporary widget\n",
        "            loading_message = HTML(\n",
        "                \"<h4 style='color: #6aa84f; margin-top: 15px;'>\"\n",
        "                \"‚è≥ Analyzing... Please wait for Cloud AI response.\"\n",
        "                \"</h4>\"\n",
        "            )\n",
        "            display(loading_message)\n",
        "\n",
        "            # --- Unified Analysis (Gemini or MobileNet) ---\n",
        "            result_content, mode = analyze_image_unified(img_bytes)\n",
        "\n",
        "        # 3. Clear the loading message, then display the final results below the image\n",
        "        with loading_status_output:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            # --- Determine Mode and Styling ---\n",
        "            if mode == \"GEMINI_CLOUD\":\n",
        "                mode_tag = \"<span style='color: blue; font-weight: bold;'>‚òÅÔ∏è Gemini Cloud AI</span>\"\n",
        "                bg_color = \"#f9f9ff\"\n",
        "                txt_color = \"#000000\"\n",
        "            elif mode == \"LOCAL\":\n",
        "                mode_tag = \"<span style='color: green; font-weight: bold;'>üñ•Ô∏è MobileNet Local AI</span>\"\n",
        "                bg_color = \"#f7fff7\"\n",
        "                txt_color = \"#000000\"\n",
        "            else: # ERROR\n",
        "                mode_tag = \"<span style='color: red; font-weight: bold;'>‚õî ERROR</span>\"\n",
        "                bg_color = \"#ffebeb\"\n",
        "                txt_color = \"#000000\"\n",
        "\n",
        "            # 4. Display Final Results and Separator\n",
        "            display(HTML(f\"<h4>Analysis Source: {mode_tag}</h4>\"))\n",
        "            # The gemini-analysis-container class is crucial for table/list formatting\n",
        "            display(HTML(f\"<div class='gemini-analysis-container'><div style='background-color: {bg_color}; color: {txt_color}'>{result_content}</div></div>\"))\n",
        "\n",
        "        with analysis_output:\n",
        "            # Add a separator in the main output after the results for the current image\n",
        "            display(HTML(\"<hr>\"))\n",
        "\n",
        "# --- Attach Event Handlers ---\n",
        "uploader.observe(on_upload_change, names='value')\n",
        "btn_capture.on_click(on_capture_click)\n",
        "btn_prev.on_click(on_prev_click)\n",
        "bnt_next.on_click(on_next_click)\n",
        "btn_remove.on_click(on_remove_click)\n",
        "btn_analyze.on_click(on_analyze_click)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 5: ASSEMBLE AND DISPLAY UI\n",
        "# ============================================================================\n",
        "\n",
        "# Combine drop zone elements\n",
        "drop_zone_elements = widgets.VBox(\n",
        "    [drop_zone_text_content, uploader, btn_capture],\n",
        "    layout=widgets.Layout(width='90%', align_items='center')\n",
        ")\n",
        "drop_zone_elements.add_class('drop-zone-vbox')\n",
        "\n",
        "# Navigation buttons HBox\n",
        "navigation_buttons = widgets.HBox(\n",
        "    [btn_prev, btn_remove, bnt_next],\n",
        "    layout=widgets.Layout(\n",
        "        width='auto',\n",
        "        justify_content='center',\n",
        "        margin='10px auto'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Main Container\n",
        "main_container_vbox = widgets.VBox(\n",
        "    [\n",
        "        header_content,\n",
        "        drop_zone_elements,\n",
        "        image_display_output,\n",
        "        navigation_buttons,\n",
        "        btn_analyze,\n",
        "        analysis_output,\n",
        "        footer_content\n",
        "    ],\n",
        "    layout=widgets.Layout(\n",
        "        align_items='center',\n",
        "        padding='20px'\n",
        "    )\n",
        ")\n",
        "\n",
        "main_container_vbox.add_class('main-container')\n",
        "\n",
        "# Checking\n",
        "# Display the final UI\n",
        "#display(HTML(css_style))\n",
        "#display(main_container_vbox)\n",
        "\n",
        "# Initialize display and button states on load\n",
        "update_image_display()"
      ],
      "metadata": {
        "id": "xqrbkao5nDBf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "92b98110-4310-4364-d96f-55b7b99eb278"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/mobilenet_v2/feature_extraction_mobilenet_v2.py:30: FutureWarning: The class MobileNetV2FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use MobileNetV2ImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BLOCK: Screen 2 - FIXED Data Order (Sync Graph & Button) ---\n",
        "\n",
        "# !pip install ipywidgets requests matplotlib\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "import datetime\n",
        "\n",
        "# --- A. Configuration ---\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "current_state = {\n",
        "    'feed': 'temperature',\n",
        "    'limit': 10\n",
        "}\n",
        "\n",
        "# --- B. Styling (CSS) ---\n",
        "style_css = \"\"\"\n",
        "<style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n",
        "\n",
        "    .screen-container {\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        background-color: #f4f6f7;\n",
        "        padding: 15px;\n",
        "        border-radius: 15px;\n",
        "        box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
        "        width: 98%;\n",
        "        border: 1px solid #dcdcdc;\n",
        "    }\n",
        "    .header-text {\n",
        "        color: #2c3e50;\n",
        "        text-align: center;\n",
        "        margin-bottom: 20px;\n",
        "        font-weight: 700;\n",
        "        font-size: 28px;\n",
        "    }\n",
        "    .widget-label { font-size: 20px !important; color: #333 !important; }\n",
        "    .widget-html { font-size: 20px !important; }\n",
        "    .widget-text { font-size: 20px !important; }\n",
        "    .widget-button {\n",
        "        font-size: 20px !important;\n",
        "        border-radius: 12px !important;\n",
        "        font-weight: bold !important;\n",
        "    }\n",
        "    input {\n",
        "        font-size: 20px !important;\n",
        "        text-align: center !important;\n",
        "        padding: 5px !important;\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# --- C. Data Fetching ---\n",
        "\n",
        "def fetch_latest_value(feed_name):\n",
        "    \"\"\"Fetches single latest value.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(f\"{BASE_URL}/history\", params={\"feed\": feed_name, \"limit\": 1}, timeout=3)\n",
        "        data = response.json()\n",
        "        if \"data\" in data and len(data[\"data\"]) > 0:\n",
        "            return str(data[\"data\"][0][\"value\"])\n",
        "    except:\n",
        "        return \"--\"\n",
        "    return \"--\"\n",
        "\n",
        "def fetch_history_data(feed_name, limit_count):\n",
        "    \"\"\"Fetches history list.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(f\"{BASE_URL}/history\", params={\"feed\": feed_name, \"limit\": limit_count}, timeout=5)\n",
        "        data = response.json()\n",
        "        if \"data\" in data:\n",
        "            vals = [float(x['value']) for x in data['data']]\n",
        "\n",
        "            # --- FIX IS HERE ---\n",
        "            # We MUST reverse the list.\n",
        "            # Server gives: [Newest, ..., Oldest]\n",
        "            # Graph needs:  [Oldest, ..., Newest] (Left to Right)\n",
        "            vals.reverse()\n",
        "\n",
        "            return vals\n",
        "    except:\n",
        "        return []\n",
        "    return []\n",
        "\n",
        "# --- D. Widgets ---\n",
        "\n",
        "header = widgets.HTML(f\"{style_css}<div class='screen-container'><div class='header-text'>üì° IoT Sensor Monitor</div>\")\n",
        "footer = widgets.HTML(\"</div>\")\n",
        "\n",
        "btn_temp = widgets.Button(description=\"Temp: --¬∞C\", button_style='danger', layout=widgets.Layout(width='32%', height='80px'), icon='thermometer-half')\n",
        "btn_humid = widgets.Button(description=\"Humid: --%\", button_style='info', layout=widgets.Layout(width='32%', height='80px'), icon='tint')\n",
        "btn_soil = widgets.Button(description=\"Soil: --%\", button_style='success', layout=widgets.Layout(width='32%', height='80px'), icon='leaf')\n",
        "\n",
        "lbl_limit = widgets.HTML(\n",
        "    value=\"<div style='background-color: white; padding: 8px 15px; border-radius: 10px; border: 1px solid #ccc; font-weight: bold;'>Graph History(limit):</div>\",\n",
        "    layout=widgets.Layout(margin='0 10px 0 0')\n",
        ")\n",
        "\n",
        "input_limit = widgets.IntText(value=10, layout=widgets.Layout(width='80px', height='30px'))\n",
        "\n",
        "out_graph = widgets.Output(\n",
        "    layout=widgets.Layout(\n",
        "        width='100%',\n",
        "        display='flex',\n",
        "        justify_content='center',\n",
        "        align_items='center',\n",
        "        margin='20px 0 0 0'\n",
        "    )\n",
        ")\n",
        "\n",
        "# --- E. Logic ---\n",
        "\n",
        "def refresh_all_data():\n",
        "    \"\"\"Main Update Function\"\"\"\n",
        "    btn_refresh.icon = 'spin fa-spinner'\n",
        "    btn_refresh.description = ' Loading...'\n",
        "\n",
        "    # 1. Update Buttons\n",
        "    btn_temp.description = f\" Temp: {fetch_latest_value('temperature')}¬∞C\"\n",
        "    btn_humid.description = f\" Humid: {fetch_latest_value('humidity')}%\"\n",
        "    btn_soil.description = f\" Soil: {fetch_latest_value('soil')}%\"\n",
        "\n",
        "    # 2. Update Graph\n",
        "    feed = current_state['feed']\n",
        "    limit = current_state['limit']\n",
        "\n",
        "    with out_graph:\n",
        "        clear_output(wait=True)\n",
        "        values = fetch_history_data(feed, limit)\n",
        "\n",
        "        if not values:\n",
        "            print(\"‚ö†Ô∏è Server sleeping or no data. Try again.\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "            c_map = {'temperature': '#e74c3c', 'humidity': '#3498db', 'soil': '#2ecc71'}\n",
        "            c = c_map.get(feed, '#333')\n",
        "\n",
        "            plt.plot(values, marker='o', color=c, linewidth=3, label=feed.capitalize())\n",
        "            plt.fill_between(range(len(values)), values, color=c, alpha=0.1)\n",
        "\n",
        "            # Fonts\n",
        "            plt.title(f\"Live Trend: {feed.capitalize()} (Last {limit})\", fontsize=24, fontweight='bold', pad=20)\n",
        "            plt.xlabel(\"Sample Order (Oldest ‚Üí Newest)\", fontsize=18)\n",
        "            plt.ylabel(\"Sensor Value\", fontsize=18)\n",
        "            plt.tick_params(axis='both', which='major', labelsize=16)\n",
        "\n",
        "            plt.legend(fontsize=16)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    btn_refresh.icon = 'refresh'\n",
        "    btn_refresh.description = ' Sync'\n",
        "\n",
        "def highlight_button(active_btn):\n",
        "    for b in [btn_temp, btn_humid, btn_soil]:\n",
        "        b.layout.border = None\n",
        "    active_btn.layout.border = '4px solid #555'\n",
        "\n",
        "# --- F. Event Handlers ---\n",
        "\n",
        "def on_temp_click(b):\n",
        "    current_state['feed'] = 'temperature'\n",
        "    highlight_button(btn_temp)\n",
        "    refresh_all_data()\n",
        "\n",
        "def on_humid_click(b):\n",
        "    current_state['feed'] = 'humidity'\n",
        "    highlight_button(btn_humid)\n",
        "    refresh_all_data()\n",
        "\n",
        "def on_soil_click(b):\n",
        "    current_state['feed'] = 'soil'\n",
        "    highlight_button(btn_soil)\n",
        "    refresh_all_data()\n",
        "\n",
        "def on_refresh_click(b):\n",
        "    refresh_all_data()\n",
        "\n",
        "def on_limit_change(change):\n",
        "    val = change['new']\n",
        "    if val < 10: input_limit.value = 10\n",
        "    elif val > 50: input_limit.value = 50\n",
        "    else:\n",
        "        current_state['limit'] = val\n",
        "        refresh_all_data()\n",
        "\n",
        "# Connect\n",
        "btn_temp.on_click(on_temp_click)\n",
        "btn_humid.on_click(on_humid_click)\n",
        "btn_soil.on_click(on_soil_click)\n",
        "input_limit.observe(on_limit_change, names='value')\n",
        "\n",
        "# --- G. Run ---\n",
        "top_row = widgets.HBox([btn_temp, btn_humid, btn_soil], layout=widgets.Layout(justify_content='space-between', margin='0 0 20px 0'))\n",
        "ctrl_row = widgets.HBox([lbl_limit, input_limit], layout=widgets.Layout(margin='0 0 20px 0', align_items='center'))\n",
        "\n",
        "ui = widgets.VBox([header, top_row, ctrl_row, out_graph, footer])\n",
        "\n",
        "#display(ui)\n",
        "highlight_button(btn_temp)\n",
        "refresh_all_data()"
      ],
      "metadata": {
        "id": "kvybzaPFLZxJ"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- BLOCK: Screen 3 - MQTT Query Screen ---\n",
        "# import requests\n",
        "# import pandas as pd\n",
        "# import ipywidgets as widgets\n",
        "# from IPython.display import display, clear_output, HTML\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # --- CONFIGURATION ---\n",
        "# BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "# FEEDS = [\"humidity\", \"soil\", \"temperature\"]\n",
        "\n",
        "# # --- API FUNCTION ---\n",
        "# def fetch_data(feed_name, limit_count):\n",
        "#     \"\"\"Fetches data from the central server and returns the data structure and status.\"\"\"\n",
        "#     try:\n",
        "#         # Note: In a production environment, you might want to remove this print.\n",
        "#         # print(\"Note: The server may be asleep. The first request might take several seconds to wake it up.\")\n",
        "#         response = requests.get(\n",
        "#             f\"{BASE_URL}/history\",\n",
        "#             params={\"feed\": feed_name, \"limit\": limit_count}\n",
        "#         )\n",
        "#         response.raise_for_status()\n",
        "#         data = response.json()\n",
        "#         return data, \"SUCCESS\"\n",
        "#     except requests.exceptions.RequestException as e:\n",
        "#         return {\"error\": f\"Request Failed: {e}\"}, \"ERROR\"\n",
        "#     except Exception as e:\n",
        "#         return {\"error\": f\"An unexpected error occurred: {e}\"}, \"ERROR\"\n",
        "\n",
        "\n",
        "# # --- CSS DEFINITION (Style Matched Theme) ---\n",
        "# # NOTE: The CSS here is for Screen 3 only. The final CSS for all tabs should be used in the main assembly block.\n",
        "# query_css = \"\"\"\n",
        "# <style>\n",
        "#     /* Global Overrides (Ensure white background in output area) */\n",
        "#     .jp-OutputArea-output, .output_wrapper, .output {\n",
        "#         background-color: #ffffff !important;\n",
        "#     }\n",
        "#     /* ... (rest of the query_css remains unchanged) ... */\n",
        "#     .lm-TabBar, .p-TabBar {\n",
        "#         background: #f0f4f0 !important;\n",
        "#         border-bottom: 3px solid #2f7c46;\n",
        "#         padding: 0;\n",
        "#         margin: 0;\n",
        "#         width: 100% !important;\n",
        "#     }\n",
        "#     .lm-TabBar-tab, .p-TabBar-tab {\n",
        "#         background: #e6e6e6 !important;\n",
        "#         color: #555 !important;\n",
        "#         padding: 10px 18px;\n",
        "#         margin-right: 2px;\n",
        "#         border-radius: 6px 6px 0 0;\n",
        "#         border: none !important;\n",
        "#     }\n",
        "#     .lm-TabBar-tab.lm-mod-current, .p-TabBar-tab.p-mod-current {\n",
        "#         background: #2f7c46 !important;\n",
        "#         color: white !important;\n",
        "#         font-weight: bold;\n",
        "#         border-top: 3px solid #2f7c46 !important;\n",
        "#         border-bottom: none !important;\n",
        "#     }\n",
        "#     .lm-Widget.lm-TabBar-content, .p-Widget.p-TabBar-content {\n",
        "#         background-color: #ffffff !important;\n",
        "#         padding: 0;\n",
        "#         border-radius: 0 0 8px 8px;\n",
        "#         border: 1px solid #e0e0e0;\n",
        "#         box-shadow: 0 4px 12px rgba(0,0,0,0.05);\n",
        "#         width: 100% !important;\n",
        "#     }\n",
        "\n",
        "#     /* Main Container Styling (Matches Image: Pure white background, soft shadow) */\n",
        "#     .mqtt-query-container {\n",
        "#         background-color: #ffffff !important;\n",
        "#         color: #222 !important;\n",
        "#         padding: 30px;\n",
        "#         border-radius: 8px;\n",
        "#         box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
        "#         width: 100% !important;\n",
        "#         box-sizing: border-box;\n",
        "#     }\n",
        "\n",
        "#     /* Header Styles (Using a strong dark green) */\n",
        "#     .mqtt-query-container h2,h3 {\n",
        "#         color: #2f7c46 !important;\n",
        "#         border-bottom: 2px solid #e0e0e0;\n",
        "#         padding-bottom: 10px;\n",
        "#         margin-bottom: 20px;\n",
        "#     }\n",
        "#     .mqtt-query-container h4 {\n",
        "#         color: #2f7c46 !important;\n",
        "#     }\n",
        "\n",
        "#     /* Widget Input Styles */\n",
        "#     .widget-text input[type=\"text\"],\n",
        "#     .widget-dropdown select {\n",
        "#         background-color: #f8f8f8 !important;\n",
        "#         color: #222 !important;\n",
        "#         border: 1px solid #c0c0c0 !important;\n",
        "#         border-radius: 4px;\n",
        "#         padding: 5px;\n",
        "#     }\n",
        "#     .widget-label {\n",
        "#         color: #333 !important;\n",
        "#     }\n",
        "#     .widget-output * {\n",
        "#         color: #333 !important;\n",
        "#     }\n",
        "# </style>\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "# # --- WIDGET DEFINITIONS (Unchanged) ---\n",
        "# feed_dropdown = widgets.Dropdown(\n",
        "#     options=FEEDS,\n",
        "#     value='humidity',\n",
        "#     description='Feed:',\n",
        "#     disabled=False,\n",
        "#     layout=widgets.Layout()\n",
        "# )\n",
        "# feed_dropdown.add_class('custom-dropdown')\n",
        "\n",
        "# limit_input = widgets.Text(\n",
        "#     value='10',\n",
        "#     placeholder='Enter number of samples (limit)',\n",
        "#     description='Limit:',\n",
        "#     disabled=False,\n",
        "#     layout=widgets.Layout()\n",
        "# )\n",
        "\n",
        "# query_button = widgets.Button(\n",
        "#     description='Query Data (API Call)',\n",
        "#     button_style='success',\n",
        "#     icon='cloud-download',\n",
        "#     layout=widgets.Layout(width='auto', margin='20px 0 0 0')\n",
        "# )\n",
        "# query_button.style.button_color = '#2f7c46'\n",
        "\n",
        "# output_area = widgets.Output()\n",
        "\n",
        "# # --- MODIFIED EVENT HANDLER (Unchanged) ---\n",
        "# def on_query_click(b):\n",
        "#     with output_area:\n",
        "#         clear_output(wait=True)\n",
        "\n",
        "#         try:\n",
        "#             limit = int(limit_input.value)\n",
        "#             feed = feed_dropdown.value\n",
        "\n",
        "#             if limit <= 0:\n",
        "#                 print(\"Error: Limit must be a positive number.\")\n",
        "#                 return\n",
        "#             if feed not in FEEDS:\n",
        "#                 print(\"Error: Invalid feed selected.\")\n",
        "#                 return\n",
        "\n",
        "#         except ValueError:\n",
        "#             print(\"Error: Limit must be a valid integer.\")\n",
        "#             return\n",
        "\n",
        "#         print(f\"Fetching '{feed}' data with limit of {limit}...\")\n",
        "\n",
        "#         query_button.disabled = True\n",
        "#         query_button.description = 'Fetching... Please Wait.'\n",
        "#         query_button.icon = 'spinner'\n",
        "\n",
        "#         data, status = fetch_data(feed, limit)\n",
        "\n",
        "#         query_button.disabled = False\n",
        "#         query_button.description = 'Query Data (API Call)'\n",
        "#         query_button.icon = 'cloud-download'\n",
        "\n",
        "#         if status == \"ERROR\":\n",
        "#             display(widgets.HTML(f\"<h3>‚ùå API Error</h3><p style='color:red;'>{data['error']}</p>\"))\n",
        "#             return\n",
        "\n",
        "#         if \"data\" in data and data[\"data\"]:\n",
        "#             display(widgets.HTML(f\"<h3>‚úÖ Data Fetched Successfully ({len(data['data'])} Samples)</h3>\"))\n",
        "\n",
        "#             df = pd.DataFrame(data[\"data\"])\n",
        "#             df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
        "#             if feed != \"json\":\n",
        "#                 df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "\n",
        "#             # --- PANDAS STYLER SETUP ---\n",
        "#             HEADER_BG = '#2f7c46'\n",
        "#             INDEX_BG = '#f0f0f0'\n",
        "#             EVEN_ROW_BG = '#f5f5f5'\n",
        "#             ODD_ROW_BG = '#ffffff'\n",
        "#             DATA_TEXT = '#000000'\n",
        "#             BORDER_COLOR = '#e0e0e0'\n",
        "\n",
        "#             styled_df = df.style \\\n",
        "#                 .set_properties(**{\n",
        "#                     'border': f'1px solid {BORDER_COLOR}',\n",
        "#                     'color': DATA_TEXT,\n",
        "#                     'padding': '8px 12px',\n",
        "#                     'text-align': 'left',\n",
        "#                     'background-color': ODD_ROW_BG\n",
        "#                 }) \\\n",
        "#                 .set_table_styles([\n",
        "#                     {'selector': 'th:not(.index_name)', 'props': [('background-color', HEADER_BG), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
        "#                     {'selector': 'tbody th', 'props': [('background-color', INDEX_BG), ('color', DATA_TEXT), ('font-weight', 'bold'),('text-align', 'center')]},\n",
        "#                     {'selector': 'tbody tr:nth-child(even)', 'props': [('background-color', EVEN_ROW_BG)]},\n",
        "#                     {'selector': 'tbody tr:nth-child(odd)', 'props': [('background-color', ODD_ROW_BG)]},\n",
        "#                 ])\n",
        "\n",
        "#             table_container = widgets.Output(layout=widgets.Layout(width='50%', padding='0 10px 0 0'))\n",
        "#             with table_container:\n",
        "#                 display(widgets.HTML(\"<h4>Raw Data Table:</h4>\"))\n",
        "#                 display(styled_df)\n",
        "\n",
        "#             if feed != \"json\":\n",
        "#                 plot_container = widgets.Output(layout=widgets.Layout(width='50%'))\n",
        "#                 with plot_container:\n",
        "#                     display(widgets.HTML(f\"<h4>Data Visualization for '{feed}':</h4>\"))\n",
        "#                     try:\n",
        "#                         fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "#                         ax.set_facecolor('#f7f7f7')\n",
        "#                         fig.patch.set_facecolor('#ffffff')\n",
        "\n",
        "#                         df.plot(x=\"created_at\", y=\"value\", marker=\"o\", ax=ax,\n",
        "#                                 title=f\"{feed.capitalize()} over Time\", legend=False,\n",
        "#                                 color='#2f7c46')\n",
        "\n",
        "#                         ax.tick_params(colors='#333')\n",
        "#                         ax.xaxis.label.set_color('#333')\n",
        "#                         ax.yaxis.label.set_color('#333')\n",
        "#                         ax.title.set_color('#2f7c46')\n",
        "\n",
        "#                         ax.grid(True, color='#e0e0e0', linestyle='--', linewidth=0.5)\n",
        "\n",
        "#                         plt.show()\n",
        "#                     except Exception as plot_e:\n",
        "#                         print(f\"Could not generate plot: {plot_e}\")\n",
        "\n",
        "#                 hbox_layout = widgets.Layout(display='flex', flex_flow='row', align_items='flex-start', width='100%')\n",
        "#                 display(widgets.HBox([table_container, plot_container], layout=hbox_layout))\n",
        "#             else:\n",
        "#                 display(table_container)\n",
        "\n",
        "\n",
        "#         elif \"data\" in data and not data[\"data\"]:\n",
        "#             display(widgets.HTML(\"<h3>‚ö†Ô∏è No Data Found</h3><p>The server returned a successful response, but the feed contained no data.</p>\"))\n",
        "#         else:\n",
        "#             display(widgets.HTML(\"<h3>‚ùå Unexpected Server Error</h3>\"))\n",
        "#             print(\"Full response:\", data)\n",
        "\n",
        "# # Attach the handler\n",
        "# query_button.on_click(on_query_click)\n",
        "\n",
        "# # --- ASSEMBLE UI ---\n",
        "\n",
        "# query_screen_ui = widgets.VBox([\n",
        "#     widgets.HTML(\"<h2>Query Screen for MQTT Data Server</h2>\"),\n",
        "#     widgets.HTML(\"<h4>Select the feed and limit, then click 'Query Data' to fetch the history.</h4>\"),\n",
        "#     widgets.HBox([\n",
        "#         widgets.VBox([feed_dropdown], layout=widgets.Layout(margin='0 10px 0 0')),\n",
        "#         widgets.VBox([limit_input])\n",
        "#     ], layout=widgets.Layout(justify_content='center', margin='20px 0')),\n",
        "#     query_button,\n",
        "#     widgets.HTML(\"<hr>\"),\n",
        "#     output_area\n",
        "# ])\n",
        "\n",
        "# # Use the throwaway variable '_' to suppress the display output of the add_class method's return value (which is the widget object in some environments)\n",
        "# _ = query_screen_ui.add_class('mqtt-query-container')\n",
        "\n",
        "# # This final line, which evaluates to None, will be the last expression.\n",
        "# None\n",
        "# #display(query_screen_ui)"
      ],
      "metadata": {
        "id": "-8fIkTVeqlOQ"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPORTS (Changed) ---\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import os\n",
        "# REMOVED: from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata # Colab specific module for accessing secrets\n",
        "import time\n",
        "\n",
        "# --- Global State and Initialization (Changed) ---\n",
        "rag_context_content = \"\"\n",
        "rag_ranked_urls_list = []\n",
        "gemini_model = None  # Global variable for the Gemini GenerativeModel\n",
        "client = None        # We'll use this for the underlying genai.Client if needed\n",
        "\n",
        "# --- UI Widgets (Key Input REMOVED) ---\n",
        "# Title and description\n",
        "title_html = widgets.HTML(\"<h2>ü§ñ Ecological RAG Query (Powered by Gemini)</h2>\")\n",
        "description_html = widgets.HTML(\"<p>Ask a question based on the pre-indexed academic papers using the Gemini 2.5 Flash model.</p>\")\n",
        "\n",
        "# API Key Input (REMOVED - Key is now loaded from Colab Secrets)\n",
        "\n",
        "# User Input Form (Remains the same)\n",
        "user_query_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder=\"e.g., What are the main components of a standard RAG system?\",\n",
        "    description='Your Question:',\n",
        "    layout=widgets.Layout(width='auto', height='150px')\n",
        ")\n",
        "\n",
        "top_k_slider = widgets.IntSlider(\n",
        "    value=3,\n",
        "    min=1,\n",
        "    max=10,\n",
        "    step=1,\n",
        "    description='Top K documents:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d',\n",
        "    layout=widgets.Layout(width='auto')\n",
        ")\n",
        "\n",
        "submit_button = widgets.Button(\n",
        "    description='Generate Answer',\n",
        "    button_style='success',\n",
        "    icon='question-circle',\n",
        "    layout=widgets.Layout(width='auto')\n",
        ")\n",
        "\n",
        "# Status/Output areas\n",
        "status_output = widgets.Output()\n",
        "answer_output = widgets.Output()\n",
        "details_output = widgets.Output()\n",
        "\n",
        "\n",
        "# --- Initialization Logic (Converted to Gemini) ---\n",
        "def initialize_gemini_client():\n",
        "    \"\"\"Initializes the global Gemini client using the Colab Secret.\"\"\"\n",
        "    global gemini_model, client\n",
        "\n",
        "    with status_output:\n",
        "        clear_output()\n",
        "        display(HTML(\"<p>Attempting to load Gemini API Key from Colab Secrets...</p>\"))\n",
        "\n",
        "    try:\n",
        "        # Load the key securely\n",
        "        gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "        if gemini_key:\n",
        "            # Configure the SDK globally\n",
        "            genai.configure(api_key=gemini_key)\n",
        "\n",
        "            # Initialize the GenerativeModel object\n",
        "            gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "            with status_output:\n",
        "                clear_output()\n",
        "                display(HTML(\"<p style='color:green; font-weight:bold;'>‚úÖ Gemini Client Connected!</p>\"))\n",
        "        else:\n",
        "            with status_output:\n",
        "                clear_output()\n",
        "                display(HTML(\"<p style='color:red;'>‚ùå GEMINI_API_KEY not found in Colab Secrets. AI disabled.</p>\"))\n",
        "                gemini_model = None\n",
        "\n",
        "    except NameError:\n",
        "        with status_output:\n",
        "            clear_output()\n",
        "            display(HTML(\"‚ö†Ô∏è Colab userdata module not available (not in Colab?). AI disabled.\"))\n",
        "            gemini_model = None\n",
        "    except Exception as e:\n",
        "        with status_output:\n",
        "            clear_output()\n",
        "            display(HTML(f\"<p style='color:red;'>‚ùå Connection Error: {e.__class__.__name__}. Check key access.</p>\"))\n",
        "            gemini_model = None\n",
        "\n",
        "# --- RAG Answer Function (External Dependency) ---\n",
        "# NOTE: This function must be defined globally for the handler to call it.\n",
        "# Assuming you defined the Gemini version of rag_answer function from the previous response.\n",
        "# If not, you must define it now, or integrate its logic directly into on_submit_click.\n",
        "# We will define a minimal Gemini RAG function here for completeness:\n",
        "\n",
        "def rag_answer(query, context):\n",
        "    \"\"\"Generates an answer using the global gemini_model based on context.\"\"\"\n",
        "    global gemini_model\n",
        "\n",
        "    # System instruction for grounded generation\n",
        "    system_instruction=(\n",
        "        \"You are an expert ecological research assistant. \"\n",
        "        \"Answer the question using ONLY the provided academic paper excerpts. \"\n",
        "        \"If the context is insufficient, state clearly that you don't have enough information from the provided papers. \"\n",
        "        \"Do not use outside knowledge.\"\n",
        "    )\n",
        "\n",
        "    # Send the combined content (instruction + context + query)\n",
        "    try:\n",
        "        response = gemini_model.generate_content(\n",
        "            contents=[context + \"\\n\\nQuestion: \" + query],\n",
        "            config=genai.types.GenerateContentConfig(\n",
        "                system_instruction=system_instruction,\n",
        "                max_output_tokens=512,\n",
        "                temperature=0.1\n",
        "            )\n",
        "        )\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"ERROR during Gemini API call: {e.__class__.__name__}: {str(e)}\"\n",
        "\n",
        "# --- Event Handler (Modified) ---\n",
        "def on_submit_click(b):\n",
        "    global rag_context_content, rag_ranked_urls_list, gemini_model\n",
        "\n",
        "    submit_button.disabled = True\n",
        "\n",
        "    # --- 1. Key and Client Check (Now calls Gemini initializer) ---\n",
        "    if gemini_model is None:\n",
        "        # Attempt to initialize client on first click if not already connected\n",
        "        initialize_gemini_client()\n",
        "\n",
        "    if gemini_model is None:\n",
        "        # Final check if initialization failed\n",
        "        with answer_output:\n",
        "            clear_output()\n",
        "            display(HTML(\"<p style='color:red; font-weight:bold;'>üö® ERROR: Gemini client not connected. Please check your API key in Colab Secrets.</p>\"))\n",
        "        submit_button.disabled = False\n",
        "        return\n",
        "\n",
        "    # Check for empty query\n",
        "    if not user_query_input.value:\n",
        "        with answer_output:\n",
        "            clear_output()\n",
        "            display(HTML(\"<p style='color: orange;'>Please enter a question to generate an answer.</p>\"))\n",
        "        submit_button.disabled = False\n",
        "        return\n",
        "\n",
        "    # --- 2. RAG Process (Retrieval and Generation) ---\n",
        "    with answer_output:\n",
        "        clear_output()\n",
        "        display(HTML(\"<h3>‚ú® Generated Answer</h3>\"))\n",
        "        display(HTML(\"<p>Generating answer... Please wait.</p>\"))\n",
        "\n",
        "    with details_output:\n",
        "        clear_output()\n",
        "        display(HTML(\"<h3>üîç RAG Process Details (Context & Sources)</h3>\"))\n",
        "        display(HTML(\"<p>Retrieving documents and building context...</p>\"))\n",
        "\n",
        "    try:\n",
        "        # A. Retrieval (Assumes retrieve_urls, index_urls, etc., are defined globally)\n",
        "        # We need to make sure the globals (index_urls, documents, urls, url_to_doc) are defined\n",
        "        # for this part to work. Since they are mock/user-defined variables, they are assumed.\n",
        "        import time\n",
        "        time.sleep(1) # Simulate retrieval time\n",
        "\n",
        "        # --- MOCK/PLACEHOLDER RAG VARIABLES (MUST REPLACE WITH YOURS) ---\n",
        "        # If your actual RAG variables (index_urls, documents, etc.) are not available,\n",
        "        # the following lines will crash. You MUST ensure they are loaded/defined.\n",
        "        # For the purpose of showing the UI working, we'll assume a minimal mock exists:\n",
        "\n",
        "        # MOCK VARIABLES ASSUMPTION:\n",
        "        global MOCK_DOCUMENTS, MOCK_URLS, MOCK_URL_TO_DOC # Assume these are defined earlier\n",
        "\n",
        "        # Using a mock retrieve_urls for demonstration\n",
        "        # NOTE: YOU MUST REPLACE THIS WITH YOUR REAL retrieve_urls FUNCTION!\n",
        "        ranked_docs = retrieve_urls(user_query_input.value, index_urls=urls, top_k=top_k_slider.value)\n",
        "\n",
        "        rag_ranked_urls_list = ranked_docs # Store for display\n",
        "\n",
        "        # B. Context Building\n",
        "        context_parts = []\n",
        "        if not ranked_docs:\n",
        "            answer_text = \"I couldn't retrieve any relevant academic paper excerpts to answer your question.\"\n",
        "        else:\n",
        "            for url, score in ranked_docs:\n",
        "                doc_idx = url_to_doc.get(url)\n",
        "                if doc_idx is not None and doc_idx < len(documents):\n",
        "                    text = documents[doc_idx]\n",
        "                    context_parts.append(f\"URL: {url}\\nScore: {score:.4f}\\nContent:\\n{text[:2000]}\") # Truncate for prompt\n",
        "                else:\n",
        "                    context_parts.append(f\"URL: {url}\\nScore: {score:.4f}\\nContent: [Document text could not be found.]\")\n",
        "\n",
        "            rag_context_content = \"\\n\\n---\\n\\n\".join(context_parts)\n",
        "\n",
        "            # C. Generation (Calls the simplified rag_answer)\n",
        "            answer_text = rag_answer(user_query_input.value, rag_context_content)\n",
        "\n",
        "\n",
        "        # D. Display Results\n",
        "        with answer_output:\n",
        "            clear_output()\n",
        "            display(HTML(\"<h3>‚ú® Generated Answer</h3>\"))\n",
        "            # Display answer in a styled box\n",
        "            display(HTML(f\"<div style='border: 1px solid #cce5ff; background-color: #e0f2f7; padding: 10px; border-radius: 5px;'>{answer_text}</div>\"))\n",
        "\n",
        "        with details_output:\n",
        "            clear_output()\n",
        "            # 1. Retrieved Documents\n",
        "            display(HTML(\"<h4>üìö Top Retrieved Documents</h4>\"))\n",
        "            if rag_ranked_urls_list:\n",
        "                for i, (url, score) in enumerate(rag_ranked_urls_list):\n",
        "                    display(HTML(f\"<strong>{i+1}.</strong> <strong>Score:</strong> <code>{score:.4f}</code> | <strong>URL:</strong> <a href='{url}' target='_blank'>{url}</a>\"))\n",
        "            else:\n",
        "                display(HTML(\"<p style='color: orange;'>No relevant documents were retrieved.</p>\"))\n",
        "\n",
        "            display(HTML(\"<hr>\"))\n",
        "\n",
        "            # 2. Context Sent to LLM\n",
        "            display(HTML(\"<h4>üìù Full Context Sent to LLM (Gemini 2.5 Flash)</h4>\"))\n",
        "            display(widgets.Textarea(\n",
        "                value=rag_context_content if rag_context_content else \"No context was available or sent to the LLM.\",\n",
        "                layout=widgets.Layout(width='100%', height='300px'),\n",
        "                disabled=True\n",
        "            ))\n",
        "\n",
        "    except Exception as e:\n",
        "        with answer_output:\n",
        "            clear_output()\n",
        "            display(HTML(\"<h3>Error</h3>\"))\n",
        "            display(HTML(f\"<p style='color: red;'>An error occurred during RAG: {e}</p>\"))\n",
        "        with details_output:\n",
        "            clear_output()\n",
        "\n",
        "    submit_button.disabled = False\n",
        "\n",
        "submit_button.on_click(on_submit_click)\n",
        "\n",
        "\n",
        "# --- Assemble UI ---\n",
        "# Initialize client automatically on assembly (good user experience)\n",
        "# NOTE: This ensures the status message shows immediately upon execution\n",
        "initialize_gemini_client()\n",
        "\n",
        "query_screen_ui = widgets.VBox([\n",
        "    title_html,\n",
        "    description_html,\n",
        "\n",
        "    # API Key Status Row (Replaces the input field)\n",
        "    widgets.HBox([widgets.Label(\"Gemini API Status:\"), status_output], layout=widgets.Layout(justify_content='space-between', align_items='center')),\n",
        "\n",
        "    widgets.HBox([widgets.Label(\"Your Question:\"), user_query_input], layout=widgets.Layout(align_items='flex-start')),\n",
        "    top_k_slider,\n",
        "    submit_button,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    answer_output,\n",
        "    details_output\n",
        "], layout=widgets.Layout(\n",
        "    width='auto'\n",
        "))\n",
        "\n",
        "query_screen_ui.add_class('rag-main-container')\n",
        "display(query_screen_ui)"
      ],
      "metadata": {
        "id": "ltzZmIJ5OqtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BLOCK 2: Screen 4 - Visual Dashboard ---\n",
        "\n",
        "# 1. Imports\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # Used for generating graph data\n",
        "\n",
        "# --- A. Setup & Styles ---\n",
        "# CSS for the status cards\n",
        "card_style = \"\"\"\n",
        "<style>\n",
        ".card {\n",
        "    background-color: #f8f9fa;\n",
        "    border-radius: 10px;\n",
        "    padding: 15px;\n",
        "    text-align: center;\n",
        "    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);\n",
        "    margin: 5px;\n",
        "    font-family: Arial, sans-serif;\n",
        "}\n",
        ".metric-value { font-size: 24px; font-weight: bold; color: #333; }\n",
        ".metric-label { font-size: 14px; color: #777; }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# --- B. Dashboard Components ---\n",
        "\n",
        "# 1. Header\n",
        "dashboard_header = widgets.HTML(\n",
        "    value=f\"{card_style}<h2 style='text-align: center; color: #196F3D;'>üåø Smart Garden Dashboard</h2>\"\n",
        ")\n",
        "\n",
        "# 2. Status Indicators (HTML Widgets)\n",
        "# These act as \"Cards\" showing current values\n",
        "temp_card = widgets.HTML(value=\"<div class='card'><div class='metric-value'>-- ¬∞C</div><div class='metric-label'>Temperature</div></div>\")\n",
        "humid_card = widgets.HTML(value=\"<div class='card'><div class='metric-value'>-- %</div><div class='metric-label'>Humidity</div></div>\")\n",
        "soil_card = widgets.HTML(value=\"<div class='card'><div class='metric-value'>-- %</div><div class='metric-label'>Soil Moisture</div></div>\")\n",
        "\n",
        "# 3. Main Status Message\n",
        "status_message = widgets.HTML(\n",
        "    value=\"<div style='background-color: #ddd; padding: 10px; text-align: center; border-radius: 5px;'>Waiting for data...</div>\"\n",
        ")\n",
        "\n",
        "# 4. Refresh Button\n",
        "btn_refresh = widgets.Button(\n",
        "    description='üîÑ Refresh Data',\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(width='100%'),\n",
        "    icon='chart-line'\n",
        ")\n",
        "\n",
        "# 5. Graph Output Area\n",
        "graph_output = widgets.Output()\n",
        "\n",
        "# --- C. Logic & Visualization Functions ---\n",
        "\n",
        "def get_status_color(moisture):\n",
        "    \"\"\"\n",
        "    Determines status color based on soil moisture.\n",
        "    Returns a HTML color string.\n",
        "    \"\"\"\n",
        "    if moisture < 30:\n",
        "        return \"#E74C3C\" # Red (Critical)\n",
        "    elif moisture < 50:\n",
        "        return \"#F1C40F\" # Yellow (Warning)\n",
        "    else:\n",
        "        return \"#2ECC71\" # Green (Good)\n",
        "\n",
        "def update_dashboard(b):\n",
        "    \"\"\"\n",
        "    Fetches data (simulated) and updates all visual elements.\n",
        "    \"\"\"\n",
        "    # 1. Simulate fetching latest data from Cloud/DB\n",
        "    # In real app: data = firebase.get('/sensor_data', None)\n",
        "    current_temp = np.random.randint(20, 32)\n",
        "    current_humid = np.random.randint(40, 70)\n",
        "    current_soil = np.random.randint(20, 90)\n",
        "\n",
        "    # 2. Update Cards HTML\n",
        "    temp_card.value = f\"<div class='card'><div class='metric-value'>{current_temp}¬∞C</div><div class='metric-label'>Temperature</div></div>\"\n",
        "    humid_card.value = f\"<div class='card'><div class='metric-value'>{current_humid}%</div><div class='metric-label'>Humidity</div></div>\"\n",
        "    soil_card.value = f\"<div class='card'><div class='metric-value'>{current_soil}%</div><div class='metric-label'>Soil Moisture</div></div>\"\n",
        "\n",
        "    # 3. Logic for Plant Health Status\n",
        "    color = get_status_color(current_soil)\n",
        "    status_text = \"HEALTHY\" if current_soil > 50 else (\"NEEDS WATER\" if current_soil > 30 else \"CRITICAL\")\n",
        "\n",
        "    status_message.value = f\"\"\"\n",
        "    <div style='background-color: {color}; color: white; padding: 15px; text-align: center; border-radius: 5px; font-weight: bold; font-size: 18px;'>\n",
        "        STATUS: {status_text}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # 4. Draw Graph (Simulating history of last 10 readings)\n",
        "    with graph_output:\n",
        "        clear_output(wait=True) # Clear previous graph\n",
        "        # Create dummy history data\n",
        "        x = ['10:00', '10:05', '10:10', '10:15', '10:20']\n",
        "        y_soil = np.random.randint(30, 80, size=5)\n",
        "        y_temp = np.random.randint(22, 28, size=5)\n",
        "\n",
        "        plt.figure(figsize=(6, 3))\n",
        "        plt.plot(x, y_soil, marker='o', label='Soil Moisture (%)', color='green')\n",
        "        plt.plot(x, y_temp, marker='s', label='Temp (¬∞C)', color='orange', linestyle='--')\n",
        "        plt.title('Last 20 Minutes Trends')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# --- D. Layout Assembly ---\n",
        "# Bind event\n",
        "btn_refresh.on_click(update_dashboard)\n",
        "\n",
        "# Top row: 3 Cards\n",
        "cards_row = widgets.HBox([temp_card, humid_card, soil_card], layout=widgets.Layout(justify_content='space-between'))\n",
        "\n",
        "# Main Structure\n",
        "dashboard = widgets.VBox(\n",
        "    [dashboard_header, status_message, cards_row, btn_refresh, graph_output],\n",
        "    layout=widgets.Layout(width='600px', border='1px solid #ccc', padding='20px')\n",
        ")\n",
        "\n",
        "# Initialize with data once on load\n",
        "update_dashboard(None)\n",
        "# Checking\n",
        "#display(dashboard)"
      ],
      "metadata": {
        "id": "SF5HINHUuQ_0"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BLOCK 2: Screen 4 - Plant Dashboard (Visual Upgrade) ---\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Dashboard CSS ---\n",
        "dash_style = \"\"\"\n",
        "<style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600&display=swap');\n",
        "\n",
        "    .dash-wrapper {\n",
        "        font-family: 'Montserrat', sans-serif;\n",
        "        background-color: #ecf0f1;\n",
        "        padding: 20px;\n",
        "        border-radius: 15px;\n",
        "        width: 600px;\n",
        "        border: 1px solid #bdc3c7;\n",
        "        margin: 0 auto;\n",
        "    }\n",
        "    .dash-header {\n",
        "        display: flex;\n",
        "        align-items: center;\n",
        "        margin-bottom: 20px;\n",
        "        background-color: white;\n",
        "        padding: 15px;\n",
        "        border-radius: 10px;\n",
        "        box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
        "    }\n",
        "    .header-icon { font-size: 30px; margin-right: 15px; }\n",
        "    .header-text { font-size: 20px; font-weight: 600; color: #27ae60; }\n",
        "\n",
        "    /* KPI Cards Container */\n",
        "    .kpi-container {\n",
        "        display: flex;\n",
        "        justify-content: space-between;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "    .kpi-card {\n",
        "        background: white;\n",
        "        width: 30%;\n",
        "        padding: 15px;\n",
        "        border-radius: 12px;\n",
        "        text-align: center;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.05);\n",
        "        transition: transform 0.2s;\n",
        "    }\n",
        "    .kpi-card:hover { transform: translateY(-3px); }\n",
        "    .kpi-value { font-size: 28px; font-weight: bold; color: #2c3e50; }\n",
        "    .kpi-label { font-size: 11px; color: #95a5a6; text-transform: uppercase; letter-spacing: 1px; margin-top: 5px; }\n",
        "\n",
        "    /* Status Banner */\n",
        "    .status-banner {\n",
        "        padding: 12px;\n",
        "        border-radius: 8px;\n",
        "        text-align: center;\n",
        "        font-weight: bold;\n",
        "        color: white;\n",
        "        margin-bottom: 20px;\n",
        "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# --- 2. Widgets & Components ---\n",
        "\n",
        "header_w = widgets.HTML(f\"{dash_style}<div class='dash-wrapper'><div class='dash-header'><span class='header-icon'>üåø</span><span class='header-text'>Live Plant Analytics</span></div>\")\n",
        "\n",
        "# We will generate the KPI cards dynamically using HTML strings\n",
        "kpi_row = widgets.HTML() # Placeholder for the cards\n",
        "status_row = widgets.HTML() # Placeholder for status\n",
        "graph_out = widgets.Output()\n",
        "\n",
        "btn_refresh = widgets.Button(\n",
        "    description=' Sync Live Data',\n",
        "    icon='refresh',\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(width='100%', height='45px')\n",
        ")\n",
        "\n",
        "footer_w = widgets.HTML(\"</div>\") # Close dash-wrapper\n",
        "\n",
        "# --- 3. Logic & Visualization ---\n",
        "\n",
        "def generate_kpi_html(temp, humid, soil):\n",
        "    return f\"\"\"\n",
        "    <div class='kpi-container'>\n",
        "        <div class='kpi-card' style='border-bottom: 4px solid #e74c3c'>\n",
        "            <div class='kpi-value'>{temp}¬∞</div>\n",
        "            <div class='kpi-label'>Temperature</div>\n",
        "        </div>\n",
        "        <div class='kpi-card' style='border-bottom: 4px solid #3498db'>\n",
        "            <div class='kpi-value'>{humid}%</div>\n",
        "            <div class='kpi-label'>Air Humidity</div>\n",
        "        </div>\n",
        "        <div class='kpi-card' style='border-bottom: 4px solid #2ecc71'>\n",
        "            <div class='kpi-value'>{soil}%</div>\n",
        "            <div class='kpi-label'>Soil Moist.</div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "def update_ui(b):\n",
        "    # 1. Simulate Data\n",
        "    t = np.random.randint(22, 30)\n",
        "    h = np.random.randint(45, 65)\n",
        "    s = np.random.randint(20, 95)\n",
        "\n",
        "    # 2. Update HTML Widgets\n",
        "    kpi_row.value = generate_kpi_html(t, h, s)\n",
        "\n",
        "    # Determine Status\n",
        "    if s < 30:\n",
        "        bg, txt = \"#c0392b\", \"CRITICAL: WATER NEEDED\" # Red\n",
        "    elif s < 50:\n",
        "        bg, txt = \"#f39c12\", \"WARNING: SOIL DRYING\" # Orange\n",
        "    else:\n",
        "        bg, txt = \"#27ae60\", \"SYSTEM OPTIMAL\" # Green\n",
        "\n",
        "    status_row.value = f\"<div class='status-banner' style='background-color: {bg};'>{txt}</div>\"\n",
        "\n",
        "    # 3. Update Graph (Matplotlib with style)\n",
        "    with graph_out:\n",
        "        clear_output(wait=True)\n",
        "        plt.style.use('seaborn-v0_8-whitegrid') # Modern clean style\n",
        "        fig, ax = plt.subplots(figsize=(8, 3.5))\n",
        "\n",
        "        # Dummy history\n",
        "        x = ['10:00', '10:05', '10:10', '10:15', '10:20', '10:25']\n",
        "        y = np.random.randint(s-10, s+10, size=6)\n",
        "\n",
        "        # Plot with gradient-like fill (using fill_between)\n",
        "        ax.plot(x, y, color=bg, linewidth=3, marker='o')\n",
        "        ax.fill_between(x, y, alpha=0.2, color=bg)\n",
        "\n",
        "        # Customizing the chart to remove \"ugly\" borders\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['left'].set_visible(False)\n",
        "        ax.spines['bottom'].set_color('#BDC3C7')\n",
        "        ax.tick_params(axis='x', colors='#7F8C8D')\n",
        "        ax.tick_params(axis='y', colors='#7F8C8D')\n",
        "        ax.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "        plt.title('Soil Moisture Trend (Last 30m)', fontsize=10, color='#7F8C8D', loc='left')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "btn_refresh.on_click(update_ui)\n",
        "\n",
        "# Initial Load\n",
        "update_ui(None)\n",
        "\n",
        "# --- 4. Assembly ---\n",
        "dash = widgets.VBox(\n",
        "    [header_w, kpi_row, status_row, graph_out, btn_refresh, footer_w]\n",
        ")\n",
        "# Checking\n",
        "#display(dash)"
      ],
      "metadata": {
        "id": "g0NZ8Q0MxDqw"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# The rest of your Python code remains the same, as the fix is purely CSS-based.\n",
        "# ... (Part A, B, and C of your Python code) ...\n",
        "button_style_fix = \"\"\"\n",
        "<style>button {\n",
        "  display: flex !important;\n",
        "  justify-content: center !important; /* Centers text horizontally */\n",
        "  align-items: center !important;   /* Centers text vertically */\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "# 1. Create the main Tab widget\n",
        "main_tabs = widgets.Tab()\n",
        "\n",
        "# 2. Assign the screen widgets to the Tab's children list\n",
        "# NOTE: The variables main_container_vbox, ui, query_screen_ui, and dash\n",
        "# must be defined in previous cells for this code block to run.\n",
        "main_tabs.children = [\n",
        "    main_container_vbox,\n",
        "    ui,\n",
        "    query_screen_ui,\n",
        "    dash\n",
        "    # search_engine_tab\n",
        "]\n",
        "\n",
        "# 3. Set the titles for each tab (Index starts at 0)\n",
        "main_tabs.set_title(0, \"1. Image Upload & Analysis\")\n",
        "main_tabs.set_title(1, \"2. Sensor Data Sampling Control\")\n",
        "main_tabs.set_title(2, \"3. MQTT Data Query\")\n",
        "main_tabs.set_title(3, \"4. Visual Dashboard\")\n",
        "# Optional: If your original CSS was defined globally and needs to be printed once:\n",
        "display(HTML(button_style_fix))\n",
        "display(HTML(css_style))\n",
        "display(HTML(dash_style))\n",
        "display(HTML(style_css))\n",
        "display(HTML(query_css))\n",
        "# 4. Final Display\n",
        "display(main_tabs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JPkO2rL5xbMq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}